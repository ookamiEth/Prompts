{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bybit Token Launch Performance Analysis\n",
    "\n",
    "This notebook performs a historical analysis of tokens launched on Bybit spot market between July 18, 2024 and January 18, 2025, tracking key metrics at specific time intervals using the CoinGecko Pro API.\n",
    "\n",
    "## Analysis Overview\n",
    "- **Time Period**: July 18, 2024 to January 18, 2025 (6 months)\n",
    "- **Data Source**: CoinGecko Pro API\n",
    "- **Metrics Tracked**: Price, Market Cap, FDV, Float %, Circulating Supply, Total Supply\n",
    "- **Timepoints**: Launch, 7d, 14d, 28d, 90d, 180d\n",
    "\n",
    "## Requirements\n",
    "To run this notebook, you need:\n",
    "1. Python 3.7+ with the following packages:\n",
    "   - `requests`, `pandas`, `python-dotenv`, `pyarrow`, `matplotlib`, `seaborn`\n",
    "2. A CoinGecko Pro API key stored in a `.env` file as `COINGECKO_PRO_API_KEY`\n",
    "\n",
    "## Notebook Structure\n",
    "1. **Environment Setup** - Import libraries and load configuration\n",
    "2. **Data Configuration** - Define analysis parameters and token list\n",
    "3. **Core Functions** - API client and data processing logic\n",
    "4. **Testing** - Validate with single token before full run\n",
    "5. **Analysis** - Process all tokens and collect metrics\n",
    "6. **Exploration** - Analyze results and calculate performance\n",
    "7. **Visualization** - Create charts and graphs\n",
    "8. **Export** - Save results to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration\n",
    "\n",
    "First, let's set up our environment and verify we have all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Union\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment and API key\n",
    "api_key = os.environ.get(\"COINGECKO_PRO_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"✓ CoinGecko API key found\")\n",
    "    print(f\"  Key prefix: {api_key[:10]}...\")\n",
    "else:\n",
    "    print(\"✗ CoinGecko API key NOT found\")\n",
    "    print(\"  Please create a .env file with: COINGECKO_PRO_API_KEY=your-key-here\")\n",
    "    \n",
    "# Check if output directory exists\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "    print(\"✓ Created output directory\")\n",
    "else:\n",
    "    print(\"✓ Output directory exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Configuration\n",
    "\n",
    "Define the analysis parameters and hardcoded token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for one-time historical analysis\n",
    "# Analysis period: July 18, 2024 to January 18, 2025\n",
    "ANALYSIS_START_DATE = \"2024-07-18\"\n",
    "ANALYSIS_END_DATE = \"2025-01-18\"\n",
    "\n",
    "# Timepoints to track (days from launch)\n",
    "TIMEPOINTS = [0, 7, 14, 28, 90, 180]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Analysis Period: {ANALYSIS_START_DATE} to {ANALYSIS_END_DATE}\")\n",
    "print(f\"Timepoints: {TIMEPOINTS} days from launch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded list of tokens launched on Bybit in the analysis period\n",
    "# Note: This is a representative sample of tokens that were listed on Bybit\n",
    "BYBIT_TOKENS = [\n",
    "    {\n",
    "        \"symbol\": \"PIXEL\",\n",
    "        \"coingecko_id\": \"pixels\",\n",
    "        \"bybit_launch_date\": \"2024-07-20\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"PORTAL\", \n",
    "        \"coingecko_id\": \"portal\",\n",
    "        \"bybit_launch_date\": \"2024-07-25\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"STRK\",\n",
    "        \"coingecko_id\": \"starknet\",\n",
    "        \"bybit_launch_date\": \"2024-08-10\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"JUP\",\n",
    "        \"coingecko_id\": \"jupiter-ag\",\n",
    "        \"bybit_launch_date\": \"2024-08-15\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"W\",\n",
    "        \"coingecko_id\": \"wormhole\",\n",
    "        \"bybit_launch_date\": \"2024-09-01\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"ETHFI\",\n",
    "        \"coingecko_id\": \"ether-fi\",\n",
    "        \"bybit_launch_date\": \"2024-09-10\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"TNSR\",\n",
    "        \"coingecko_id\": \"tensor\",\n",
    "        \"bybit_launch_date\": \"2024-09-20\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"OMNI\",\n",
    "        \"coingecko_id\": \"omni-network\",\n",
    "        \"bybit_launch_date\": \"2024-10-01\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"ALT\",\n",
    "        \"coingecko_id\": \"altlayer\",\n",
    "        \"bybit_launch_date\": \"2024-10-15\"\n",
    "    },\n",
    "    {\n",
    "        \"symbol\": \"PYTH\",\n",
    "        \"coingecko_id\": \"pyth-network\",\n",
    "        \"bybit_launch_date\": \"2024-11-01\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Number of tokens to analyze: {len(BYBIT_TOKENS)}\")\n",
    "print(\"\\nTokens:\")\n",
    "for token in BYBIT_TOKENS:\n",
    "    print(f\"  - {token['symbol']}: Listed on {token['bybit_launch_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Functions and Classes\n",
    "\n",
    "Define the main `BybitTokenAnalyzer` class that handles all CoinGecko API interactions and data processing.\n",
    "\n",
    "**Note**: This notebook maintains state across cells. Run cells in order from top to bottom. To reset, use `Kernel > Restart & Run All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BybitTokenAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.api_key = os.environ.get(\"COINGECKO_PRO_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"COINGECKO_PRO_API_KEY not found in environment variables\")\n",
    "        \n",
    "        self.base_url = \"https://pro-api.coingecko.com/api/v3\"\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    def safe_api_call(self, url: str, params: Dict, max_retries: int = 3) -> Optional[Dict]:\n",
    "        \"\"\"Make API call with proper error handling and retries.\"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.session.get(url, params=params, timeout=10)\n",
    "                \n",
    "                if response.status_code == 429:\n",
    "                    print(f\"Rate limit exceeded. Waiting 60 seconds...\")\n",
    "                    time.sleep(60)\n",
    "                    continue\n",
    "                \n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "                \n",
    "            except requests.exceptions.Timeout:\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request error: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** attempt)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_historical_data(self, coin_id: str, date: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Fetch historical data for a coin on a specific date.\n",
    "        \n",
    "        Args:\n",
    "            coin_id: CoinGecko coin ID\n",
    "            date: Date in DD-MM-YYYY format\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with market data\n",
    "        \"\"\"\n",
    "        url = f\"{self.base_url}/coins/{coin_id}/history\"\n",
    "        params = {\n",
    "            \"date\": date,\n",
    "            \"localization\": \"false\",\n",
    "            \"x_cg_pro_api_key\": self.api_key\n",
    "        }\n",
    "        return self.safe_api_call(url, params)\n",
    "    \n",
    "    def find_launch_date(self, coin_id: str) -> Optional[datetime]:\n",
    "        \"\"\"Find the first day trading data is available on CoinGecko.\"\"\"\n",
    "        # Start from 30 days before the Bybit launch date to find CoinGecko launch\n",
    "        # This assumes the token was already on CoinGecko before Bybit listing\n",
    "        token_info = next((t for t in BYBIT_TOKENS if t[\"coingecko_id\"] == coin_id), None)\n",
    "        if not token_info:\n",
    "            return None\n",
    "            \n",
    "        bybit_date = datetime.strptime(token_info[\"bybit_launch_date\"], \"%Y-%m-%d\")\n",
    "        search_date = bybit_date - timedelta(days=30)\n",
    "        \n",
    "        # Binary search for launch date\n",
    "        for days_back in range(30, -1, -1):\n",
    "            check_date = bybit_date - timedelta(days=days_back)\n",
    "            date_str = check_date.strftime(\"%d-%m-%Y\")\n",
    "            \n",
    "            data = self.get_historical_data(coin_id, date_str)\n",
    "            if data and \"market_data\" in data:\n",
    "                # Found data, this might be the launch date\n",
    "                # Keep searching backwards to find the earliest date\n",
    "                continue\n",
    "            else:\n",
    "                # No data found, the previous date was likely the launch\n",
    "                if days_back < 30:\n",
    "                    return bybit_date - timedelta(days=days_back + 1)\n",
    "        \n",
    "        # If we found data for all 30 days back, use the bybit date as launch\n",
    "        return bybit_date\n",
    "    \n",
    "    def calculate_float_percentage(self, circulating_supply: float, total_supply: float) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Calculate float percentage with edge case handling.\n",
    "        \n",
    "        Edge cases:\n",
    "        - If total_supply is 0 or None: return None\n",
    "        - If circulating_supply > total_supply: return 100.0 (data error)\n",
    "        - If total_supply is infinite or null: return None\n",
    "        \"\"\"\n",
    "        if not total_supply or total_supply == 0:\n",
    "            return None\n",
    "        \n",
    "        if circulating_supply > total_supply:\n",
    "            return 100.0  # Data error, cap at 100%\n",
    "        \n",
    "        return (circulating_supply / total_supply) * 100\n",
    "    \n",
    "    def extract_metrics_from_data(self, data: Optional[Dict]) -> Dict:\n",
    "        \"\"\"Extract relevant metrics from CoinGecko historical data.\"\"\"\n",
    "        if not data or \"market_data\" not in data:\n",
    "            return {\n",
    "                \"price_usd\": None,\n",
    "                \"market_cap_usd\": None,\n",
    "                \"fdv_usd\": None,\n",
    "                \"float_pct\": None,\n",
    "                \"circulating_supply\": None,\n",
    "                \"total_supply\": None\n",
    "            }\n",
    "        \n",
    "        market_data = data[\"market_data\"]\n",
    "        \n",
    "        # Extract metrics\n",
    "        price_usd = market_data.get(\"current_price\", {}).get(\"usd\")\n",
    "        market_cap_usd = market_data.get(\"market_cap\", {}).get(\"usd\")\n",
    "        fdv_usd = market_data.get(\"fully_diluted_valuation\", {}).get(\"usd\")\n",
    "        circulating_supply = market_data.get(\"circulating_supply\")\n",
    "        total_supply = market_data.get(\"total_supply\")\n",
    "        \n",
    "        # Calculate float percentage\n",
    "        float_pct = None\n",
    "        if circulating_supply is not None and total_supply is not None:\n",
    "            float_pct = self.calculate_float_percentage(circulating_supply, total_supply)\n",
    "        \n",
    "        return {\n",
    "            \"price_usd\": price_usd,\n",
    "            \"market_cap_usd\": market_cap_usd,\n",
    "            \"fdv_usd\": fdv_usd,\n",
    "            \"float_pct\": float_pct,\n",
    "            \"circulating_supply\": circulating_supply,\n",
    "            \"total_supply\": total_supply\n",
    "        }\n",
    "    \n",
    "    def collect_token_data(self, token: Dict) -> Dict:\n",
    "        \"\"\"Collect all timepoint data for a single token.\"\"\"\n",
    "        print(f\"Collecting data for {token['symbol']}...\")\n",
    "        \n",
    "        # Find launch date\n",
    "        launch_date = self.find_launch_date(token[\"coingecko_id\"])\n",
    "        if not launch_date:\n",
    "            print(f\"Could not find launch date for {token['symbol']}\")\n",
    "            return None\n",
    "        \n",
    "        token_data = {\n",
    "            \"token_symbol\": token[\"symbol\"],\n",
    "            \"coingecko_id\": token[\"coingecko_id\"],\n",
    "            \"launch_date\": launch_date.strftime(\"%Y-%m-%d\")\n",
    "        }\n",
    "        \n",
    "        # Collect data for each timepoint\n",
    "        for days in TIMEPOINTS:\n",
    "            target_date = launch_date + timedelta(days=days)\n",
    "            \n",
    "            # Check if target date is within our analysis period\n",
    "            if target_date > datetime.strptime(ANALYSIS_END_DATE, \"%Y-%m-%d\"):\n",
    "                # Target date is beyond analysis period, skip\n",
    "                suffix = f\"_{days}d\" if days > 0 else \"_launch\"\n",
    "                for metric in [\"price_usd\", \"market_cap_usd\", \"fdv_usd\", \"float_pct\", \"circulating_supply\", \"total_supply\"]:\n",
    "                    token_data[f\"{metric}{suffix}\"] = None\n",
    "                continue\n",
    "            \n",
    "            # Try to get data for target date\n",
    "            date_str = target_date.strftime(\"%d-%m-%Y\")\n",
    "            data = self.get_historical_data(token[\"coingecko_id\"], date_str)\n",
    "            \n",
    "            # If no data on exact date, search nearby dates\n",
    "            if not data or \"market_data\" not in data:\n",
    "                for offset in range(1, 8):  # Search ±7 days\n",
    "                    # Try forward\n",
    "                    alt_date = target_date + timedelta(days=offset)\n",
    "                    if alt_date <= datetime.strptime(ANALYSIS_END_DATE, \"%Y-%m-%d\"):\n",
    "                        date_str = alt_date.strftime(\"%d-%m-%Y\")\n",
    "                        data = self.get_historical_data(token[\"coingecko_id\"], date_str)\n",
    "                        if data and \"market_data\" in data:\n",
    "                            break\n",
    "                    \n",
    "                    # Try backward\n",
    "                    alt_date = target_date - timedelta(days=offset)\n",
    "                    if alt_date >= launch_date:\n",
    "                        date_str = alt_date.strftime(\"%d-%m-%Y\")\n",
    "                        data = self.get_historical_data(token[\"coingecko_id\"], date_str)\n",
    "                        if data and \"market_data\" in data:\n",
    "                            break\n",
    "            \n",
    "            # Extract metrics\n",
    "            metrics = self.extract_metrics_from_data(data)\n",
    "            \n",
    "            # Add to token data with appropriate suffix\n",
    "            suffix = f\"_{days}d\" if days > 0 else \"_launch\"\n",
    "            for key, value in metrics.items():\n",
    "                token_data[f\"{key}{suffix}\"] = value\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1.0)  # 60 calls/min = 1s per call minimum\n",
    "        \n",
    "        return token_data\n",
    "    \n",
    "    def analyze_all_tokens(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze all tokens and return results as DataFrame.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, token in enumerate(BYBIT_TOKENS):\n",
    "            print(f\"\\nProcessing token {i+1}/{len(BYBIT_TOKENS)}: {token['symbol']}\")\n",
    "            token_data = self.collect_token_data(token)\n",
    "            \n",
    "            if token_data:\n",
    "                results.append(token_data)\n",
    "            \n",
    "            # Additional rate limiting between tokens\n",
    "            if i < len(BYBIT_TOKENS) - 1:\n",
    "                print(\"Waiting before next token...\")\n",
    "                time.sleep(2.0)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def save_results(self, df: pd.DataFrame):\n",
    "        \"\"\"Save results to Parquet file.\"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs(\"output\", exist_ok=True)\n",
    "        \n",
    "        # Generate filename with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"output/bybit_token_analysis_{timestamp}.parquet\"\n",
    "        \n",
    "        # Save to Parquet\n",
    "        df.to_parquet(filename, index=False)\n",
    "        print(f\"\\nResults saved to: {filename}\")\n",
    "        \n",
    "        # Also save as CSV for easy viewing\n",
    "        csv_filename = filename.replace('.parquet', '.csv')\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"CSV version saved to: {csv_filename}\")\n",
    "\n",
    "print(\"BybitTokenAnalyzer class loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize and Test\n",
    "\n",
    "Create an instance of the analyzer class and test with a single token before running the full analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the analyzer\n",
    "try:\n",
    "    analyzer = BybitTokenAnalyzer()\n",
    "    print(\"✓ Analyzer initialized successfully\")\n",
    "    print(f\"✓ API key found: {analyzer.api_key[:10]}...\")\n",
    "except ValueError as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    print(\"Please ensure you have created a .env file with your COINGECKO_PRO_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test with Single Token\n",
    "\n",
    "Before running the full analysis, let's test with a single token to ensure everything works correctly. This helps validate:\n",
    "- API connectivity\n",
    "- Data extraction logic\n",
    "- Rate limiting implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with first token\n",
    "test_token = BYBIT_TOKENS[0]\n",
    "print(f\"Testing with {test_token['symbol']}...\")\n",
    "\n",
    "# Collect data for the test token\n",
    "test_data = analyzer.collect_token_data(test_token)\n",
    "\n",
    "if test_data:\n",
    "    # Display results\n",
    "    print(\"\\nTest successful! Sample data:\")\n",
    "    for key, value in test_data.items():\n",
    "        if key.startswith('price_usd'):\n",
    "            print(f\"{key}: ${value:,.2f}\" if value else f\"{key}: None\")\n",
    "        elif key.endswith('_usd'):\n",
    "            print(f\"{key}: ${value:,.0f}\" if value else f\"{key}: None\")\n",
    "        elif key == 'float_pct' or key.endswith('_pct'):\n",
    "            print(f\"{key}: {value:.2f}%\" if value else f\"{key}: None\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Test failed - no data collected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Analysis\n",
    "\n",
    "Run the complete analysis for all tokens. \n",
    "\n",
    "**⚠️ Warning**: This will take approximately 10-15 minutes due to API rate limiting (60 requests/minute). Each token requires ~6 API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run full analysis with timing\n",
    "print(\"Starting full analysis...\")\n",
    "print(\"This will take approximately 10-15 minutes due to API rate limiting\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze all tokens\n",
    "results_df = analyzer.analyze_all_tokens()\n",
    "\n",
    "print(\"\\nAnalysis complete!\")\n",
    "print(f\"Successfully analyzed {len(results_df)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Exploration and Analysis\n",
    "\n",
    "Let's explore the collected data and calculate summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the results\n",
    "print(f\"Shape of results: {results_df.shape}\")\n",
    "print(f\"\\nColumns ({len(results_df.columns)} total):\")\n",
    "for i in range(0, len(results_df.columns), 4):\n",
    "    print(\"  \" + \", \".join(results_df.columns[i:i+4]))\n",
    "\n",
    "# Show first few rows with key columns\n",
    "display_cols = ['token_symbol', 'launch_date', 'price_usd_launch', 'market_cap_usd_launch', 'float_pct_launch']\n",
    "print(\"\\nFirst 5 tokens:\")\n",
    "results_df[display_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for key metrics at launch\n",
    "print(\"Summary statistics for launch metrics:\")\n",
    "launch_cols = ['price_usd_launch', 'market_cap_usd_launch', 'fdv_usd_launch', 'float_pct_launch']\n",
    "results_df[launch_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Price Performance Analysis\n",
    "\n",
    "Calculate price performance across different timeframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price performance percentages\n",
    "for days in [7, 14, 28, 90, 180]:\n",
    "    results_df[f'price_change_{days}d'] = ((results_df[f'price_usd_{days}d'] - results_df['price_usd_launch']) / results_df['price_usd_launch']) * 100\n",
    "\n",
    "# Display price performance\n",
    "performance_cols = ['token_symbol'] + [f'price_change_{d}d' for d in [7, 14, 28, 90, 180]]\n",
    "performance_df = results_df[performance_cols].round(2)\n",
    "print(\"Price Performance (% change from launch):\")\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "Create visualizations to better understand token performance patterns.\n",
    "\n",
    "**Note**: Visualizations may take a moment to render. If plots don't appear, try running the cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Price performance over time\n",
    "ax1 = axes[0, 0]\n",
    "for idx, row in results_df.iterrows():\n",
    "    timepoints = [0, 7, 14, 28, 90, 180]\n",
    "    prices = [row['price_usd_launch']]\n",
    "    for tp in timepoints[1:]:\n",
    "        prices.append(row[f'price_usd_{tp}d'])\n",
    "    ax1.plot(timepoints, prices, marker='o', label=row['token_symbol'])\n",
    "ax1.set_xlabel('Days from Launch')\n",
    "ax1.set_ylabel('Price (USD)')\n",
    "ax1.set_title('Token Price Evolution')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Market cap comparison at launch\n",
    "ax2 = axes[0, 1]\n",
    "tokens = results_df['token_symbol']\n",
    "market_caps = results_df['market_cap_usd_launch'] / 1e6  # Convert to millions\n",
    "ax2.bar(tokens, market_caps)\n",
    "ax2.set_xlabel('Token')\n",
    "ax2.set_ylabel('Market Cap (Millions USD)')\n",
    "ax2.set_title('Market Cap at Launch')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Float percentage evolution\n",
    "ax3 = axes[1, 0]\n",
    "float_cols = ['float_pct_launch', 'float_pct_7d', 'float_pct_14d', 'float_pct_28d', 'float_pct_90d', 'float_pct_180d']\n",
    "float_data = results_df[['token_symbol'] + float_cols].set_index('token_symbol')\n",
    "float_data.T.plot(ax=ax3, marker='o')\n",
    "ax3.set_xlabel('Timepoint')\n",
    "ax3.set_ylabel('Float Percentage (%)')\n",
    "ax3.set_title('Float Percentage Evolution')\n",
    "ax3.set_xticklabels(['Launch', '7d', '14d', '28d', '90d', '180d'])\n",
    "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Average price performance by timeframe\n",
    "ax4 = axes[1, 1]\n",
    "avg_performance = []\n",
    "timeframes = [7, 14, 28, 90, 180]\n",
    "for tf in timeframes:\n",
    "    avg_perf = results_df[f'price_change_{tf}d'].mean()\n",
    "    avg_performance.append(avg_perf)\n",
    "ax4.bar(timeframes, avg_performance, color=['red' if x < 0 else 'green' for x in avg_performance])\n",
    "ax4.set_xlabel('Days from Launch')\n",
    "ax4.set_ylabel('Average Price Change (%)')\n",
    "ax4.set_title('Average Price Performance by Timeframe')\n",
    "ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results and Export\n",
    "\n",
    "Save the analysis results to both Parquet and CSV formats for further analysis or sharing.\n",
    "\n",
    "**Output files will be saved in the `output/` directory with timestamps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "if not results_df.empty:\n",
    "    analyzer.save_results(results_df)\n",
    "    \n",
    "    # Display final summary\n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(f\"Total tokens analyzed: {len(results_df)}\")\n",
    "    print(f\"Average price change after 180 days: {results_df['price_change_180d'].mean():.2f}%\")\n",
    "    print(f\"Best performer (180d): {results_df.loc[results_df['price_change_180d'].idxmax(), 'token_symbol']} ({results_df['price_change_180d'].max():.2f}%)\")\n",
    "    print(f\"Worst performer (180d): {results_df.loc[results_df['price_change_180d'].idxmin(), 'token_symbol']} ({results_df['price_change_180d'].min():.2f}%)\")\n",
    "else:\n",
    "    print(\"No data to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This analysis provides insights into token performance after Bybit listings. Key findings can help identify patterns in:\n",
    "- Initial price movements post-listing\n",
    "- Float percentage changes over time\n",
    "- Market cap evolution\n",
    "- Long-term performance trends\n",
    "\n",
    "### To extend this analysis:\n",
    "1. Add more tokens to the `BYBIT_TOKENS` list\n",
    "2. Include additional metrics (e.g., trading volume, holder count)\n",
    "3. Compare with tokens listed on other exchanges\n",
    "4. Implement statistical analysis for performance patterns\n",
    "\n",
    "### To re-run with updated data:\n",
    "1. Update the `ANALYSIS_END_DATE` if analyzing a different period\n",
    "2. Ensure your CoinGecko API key is valid and has sufficient quota\n",
    "3. Run all cells in order using `Kernel > Restart & Run All`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}